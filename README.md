# neuralNets_BackPro

In this project a Neural network model for classification of MNIST dataset has been implemented. We have used sigmoid as the activation function and cross entropy loss for the optimization. We have also carried out hyperparameter tuning to check which hyper parameter value gives best result.

Back propagation is implemented, by using the concept of computational graphs. They provide an efficient method to calculate gradients for any network structure. The hyperparameters considered for tuning were learning rate and number of layers of the neural network.
